{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3C and ACER\n",
    "\n",
    "This notebook contains test runs of two RL Algorithms.\n",
    "\n",
    "Asynchronous Advantage Actor Critic\n",
    "\n",
    "Asynchronous means multiple agents are trained at the same time and submit asynchronous weight updates to a shared model.\n",
    "The Gradients are derived from the Advantage Funktion (Q-V).\n",
    "There is a policy and a critic network, the critic network rates the Value of the actions of the policy.\n",
    "\n",
    "Actor Critic with Experience Replay uses the innovations of A3C.\n",
    "Experience Replay increses the sample Efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines.common import plot_util as pu\n",
    "import time\n",
    "from baselines.run import run, play\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict(alg='acer', \n",
    "     env='CartPole-v0', # This works well with MountainCar-v0\n",
    "     env_type=None, \n",
    "     gamestate=None,\n",
    "     log_path='./logs/acer-tmp/',\n",
    "     network=None, \n",
    "     num_env=None, \n",
    "     num_timesteps=30000.0, \n",
    "     play=False, \n",
    "     reward_scale=1.0,\n",
    "     save_path='./models/model', \n",
    "     save_video_interval=0, \n",
    "     save_video_length=200, \n",
    "     seed=0,\n",
    "     trust_region=True, \n",
    "     nsteps=128,\n",
    "     replay_ratio=4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Details\n",
    "\n",
    "The Acer implementation can be found in the a3cacerdemo/baselines/acer/acer.py file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path=\"./logs/cartpole/\"\n",
    "for seed in range(0,6):\n",
    "    run(seed=seed, trust_region=True, log_path=f\"{log_path}cartpole-{str(seed)}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pu.load_results(log_path)\n",
    "pu.plot_results(results, average_group=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the following the Trust Regions have been turned off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path=\"./logs/cartpole-notrust/\"\n",
    "for seed in range(0,3):\n",
    "    run(seed=seed,trust_region=False, log_path=f\"{log_path}cartpole-notrust-{str(seed)}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pu.load_results(log_path)\n",
    "\n",
    "pu.plot_results(results, average_group=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3C\n",
    "\n",
    "A3C can be seen as a special case of Acer with replay_ratio = 0 and no trust regions.\n",
    "It is an on-policy method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path=\"./logs/cartpole-notrust-a3c/\"\n",
    "for seed in range(0,3):\n",
    "    run(seed=seed,replay_ratio=0,trust_region=False, log_path=f\"{log_path}cartpole-notrust-a3c-{str(seed)}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pu.load_results(log_path)\n",
    "\n",
    "pu.plot_results(results, average_group=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=\"MountainCar-v0\"\n",
    "log_path=f\"./logs/{env}/\"\n",
    "\n",
    "for seed in range(0,3):\n",
    "    run(seed=seed, log_path=f\"{log_path}{env}-{str(seed)}/\", num_timesteps=3e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pu.load_results(log_path)\n",
    "\n",
    "pu.plot_results(results, average_group=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=\"MountainCar-v0\"\n",
    "play(load_path=\"./models/model\", env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=\"PongNoFrameskip-v4\"\n",
    "play(load_path=\"/home/simon/Documents/WiSe20/topicsrl/a3cacerdemo/models/pong3m\", env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "science",
   "language": "python",
   "name": "science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
